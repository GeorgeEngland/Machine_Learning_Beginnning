{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true,y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error)<1\n",
    "    squared_loss = tf.square(error)/2\n",
    "    linear_loss = tf.abs(error)-.5\n",
    "    return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error)<threshold\n",
    "        squared_loss = tf.square(error)/2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2/2\n",
    "        return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train[1,:].shape\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation = \"selu\", kernel_initializer = \"lecun_normal\",\n",
    "                      input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5835 - mae: 0.9320 - val_loss: 0.3595 - val_mae: 0.6503\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2174 - mae: 0.5141 - val_loss: 0.3124 - val_mae: 0.6027\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2084 - mae: 0.5015 - val_loss: 0.2689 - val_mae: 0.5527\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2019 - mae: 0.4929 - val_loss: 0.2290 - val_mae: 0.5124\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1965 - mae: 0.4853 - val_loss: 0.1911 - val_mae: 0.4716\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1919 - mae: 0.4784 - val_loss: 0.1794 - val_mae: 0.4585\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1903 - mae: 0.4770 - val_loss: 0.1889 - val_mae: 0.4671\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1880 - mae: 0.4731 - val_loss: 0.1805 - val_mae: 0.4570\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1860 - mae: 0.4701 - val_loss: 0.1815 - val_mae: 0.4576\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1849 - mae: 0.4678 - val_loss: 0.1816 - val_mae: 0.4547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56467ce0f0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=huber_fn,optimizer=\"nadam\",metrics=[\"mae\"])\n",
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/5_CustomModelAndTraining/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../Models/5_CustomModelAndTraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"../Models/5_CustomModelAndTraining\",\n",
    "                                custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1832 - mean_absolute_error: 0.4649 - val_loss: 0.1904 - val_mean_absolute_error: 0.4650\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1819 - mean_absolute_error: 0.4626 - val_loss: 0.1717 - val_mean_absolute_error: 0.4493\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1804 - mean_absolute_error: 0.4605 - val_loss: 0.1836 - val_mean_absolute_error: 0.4572\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1788 - mean_absolute_error: 0.4578 - val_loss: 0.1723 - val_mean_absolute_error: 0.4462\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1778 - mean_absolute_error: 0.4561 - val_loss: 0.1879 - val_mean_absolute_error: 0.4597\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1764 - mean_absolute_error: 0.4535 - val_loss: 0.1710 - val_mean_absolute_error: 0.4422\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1752 - mean_absolute_error: 0.4520 - val_loss: 0.1890 - val_mean_absolute_error: 0.4588\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1742 - mean_absolute_error: 0.4497 - val_loss: 0.1721 - val_mean_absolute_error: 0.4414\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1728 - mean_absolute_error: 0.4476 - val_loss: 0.1799 - val_mean_absolute_error: 0.4483\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1720 - mean_absolute_error: 0.4456 - val_loss: 0.1665 - val_mean_absolute_error: 0.4319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56463d9080>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Class\n",
    "### Threshold is saved with saving of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self,threshold = 1.0,**kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self,y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error)<self.threshold\n",
    "        squared_loss = tf.square(error)/2\n",
    "        linear_loss = self.threshold* tf.abs(error)-self.threshold**2/2\n",
    "        return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config,\"threshold\":self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/5_CustomModelAndTraining_HuberClass/assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=HuberLoss(2.0),optimizer=\"nadam\",metrics=[\"mae\"])\n",
    "model.save(\"../Models/5_CustomModelAndTraining_HuberClass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"../Models/5_CustomModelAndTraining_HuberClass/\",\n",
    "                               custom_objects={\"HuberLoss\":HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1909 - mean_absolute_error: 0.4478 - val_loss: 0.2263 - val_mean_absolute_error: 0.4543\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1904 - mean_absolute_error: 0.4463 - val_loss: 0.1915 - val_mean_absolute_error: 0.4409\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1879 - mean_absolute_error: 0.4441 - val_loss: 0.2135 - val_mean_absolute_error: 0.4465\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1872 - mean_absolute_error: 0.4426 - val_loss: 0.1928 - val_mean_absolute_error: 0.4391\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1865 - mean_absolute_error: 0.4414 - val_loss: 0.2180 - val_mean_absolute_error: 0.4497\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1855 - mean_absolute_error: 0.4404 - val_loss: 0.1863 - val_mean_absolute_error: 0.4353\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1851 - mean_absolute_error: 0.4399 - val_loss: 0.2313 - val_mean_absolute_error: 0.4532\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.1837 - mean_absolute_error: 0.4369 - val_loss: 0.2130 - val_mean_absolute_error: 0.4449\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.1826 - mean_absolute_error: 0.4359 - val_loss: 0.2255 - val_mean_absolute_error: 0.4470\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.1823 - mean_absolute_error: 0.4347 - val_loss: 0.1861 - val_mean_absolute_error: 0.4261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5644a76c50>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Activation, Initializer,Reularizer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z)+1.0)\n",
    "def my_glorot_initializer(shape,dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2./(shape[0]+shape[1]))\n",
    "    return tf.random.normal(shape,stddev=stddev,dtype=dtype)\n",
    "def my_li_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01*weights))\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights<0.,tf.zeros_like(weights),weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(30,activation = my_softplus,\n",
    "                          kernel_initializer = my_glorot_initializer,\n",
    "                          kernel_regularizer=my_li_regularizer,\n",
    "                          kernel_constraint = my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self,weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor*weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\":factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self,threshold=1.0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\",initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\",initializer=\"zeros\")\n",
    "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
    "        metric = self.huber_fn(y_true,y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true),tf.float32))\n",
    "    def result(self):\n",
    "        return self.total/self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config,\"threshold\":threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Better Implementation\n",
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.0923 - HuberMetric: 0.1846\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 886us/step - loss: 0.0924 - HuberMetric: 0.1847\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/5_ModelWithCustomMetric/assets\n"
     ]
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()\n",
    "model.save(\"../Models/5_ModelWithCustomMetric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([MyDense(30, activation = 'relu', input_shape=input_shape),\n",
    "                                MyDense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5663 - val_loss: 1.0096\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6399 - val_loss: 0.5205\n",
      "162/162 [==============================] - 0s 696us/step - loss: 0.5548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5548022389411926"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self,stddev,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "    def call(self,X,training = None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X),stddev=self.stddev)\n",
    "            return noise + X\n",
    "        else:\n",
    "            return X\n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        return batch_input_shape\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layers and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self,n_layers,n_neurons,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons,activation=\"relu\",\n",
    "                                         kernel_initializer = \"he_normal\")\n",
    "                      for _ in range(n_layers)]\n",
    "    def call(self,inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.Model):\n",
    "    def __init__(self,output_dim,**kwags):\n",
    "        super().__init__(**kwags)\n",
    "        self.hidden1 = keras.layers.Dense(30,activation=\"elu\",\n",
    "                                          kernel_initializer = \"he_normal\")\n",
    "        self.block1 = ResidualBlock(2,30)\n",
    "        self.block2 = ResidualBlock(2,30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "    def call(self, inputs):\n",
    "        Z= self.hidden1(inputs)\n",
    "        for _ in range (1+3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 30.5819\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.5190\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7493\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7732\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8121\n",
      "162/162 [==============================] - 0s 778us/step - loss: 0.8806\n",
      "Model: \"residual_regressor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             multiple                  270       \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc multiple                  1860      \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl multiple                  1860      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             multiple                  31        \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_new_scaled = X_test_scaled\n",
    "\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/5_CustomLayerModel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../Models/5_CustomLayerModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReconstructingRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        # TODO: check https://github.com/tensorflow/tensorflow/issues/26260\n",
    "        #self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        self.recon_loss = 0.05 * tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        return self.out(Z)\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=[self.recon_loss])\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.6870\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4027\n"
     ]
    }
   ],
   "source": [
    "keras.losses.Loss()\n",
    "model2 = ReconstructingRegressor(1)\n",
    "model2.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model2.fit(X_train_scaled, y_train, epochs=2)\n",
    "#y_pred = model.predict(X_test_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
