{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true,y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error)<1\n",
    "    squared_loss = tf.square(error)/2\n",
    "    linear_loss = tf.abs(error)-.5\n",
    "    return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error)<threshold\n",
    "        squared_loss = tf.square(error)/2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2/2\n",
    "        return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train[1,:].shape\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation = \"selu\", kernel_initializer = \"lecun_normal\",\n",
    "                      input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5986 - mae: 0.9701 - val_loss: 0.2257 - val_mae: 0.5257\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2159 - mae: 0.5134 - val_loss: 0.1981 - val_mae: 0.4805\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2033 - mae: 0.4949 - val_loss: 0.2073 - val_mae: 0.4867\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.1987 - mae: 0.4878 - val_loss: 0.2038 - val_mae: 0.4858\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.1946 - mae: 0.4809 - val_loss: 0.1881 - val_mae: 0.4636\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1913 - mae: 0.4755 - val_loss: 0.1866 - val_mae: 0.4653\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1881 - mae: 0.4707 - val_loss: 0.1809 - val_mae: 0.4516\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1848 - mae: 0.4647 - val_loss: 0.1695 - val_mae: 0.4417\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1815 - mae: 0.4596 - val_loss: 0.1974 - val_mae: 0.4694\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1796 - mae: 0.4564 - val_loss: 0.1715 - val_mae: 0.4439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff226ea53c8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=huber_fn,optimizer=\"nadam\",metrics=[\"mae\"])\n",
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/5_CustomModelAndTraining/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../Models/5_CustomModelAndTraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"../Models/5_CustomModelAndTraining\",\n",
    "                                custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1774 - mean_absolute_error: 0.4537 - val_loss: 0.1766 - val_mean_absolute_error: 0.4487\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1754 - mean_absolute_error: 0.4498 - val_loss: 0.1620 - val_mean_absolute_error: 0.4305\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1733 - mean_absolute_error: 0.4463 - val_loss: 0.1715 - val_mean_absolute_error: 0.4389\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1718 - mean_absolute_error: 0.4432 - val_loss: 0.1710 - val_mean_absolute_error: 0.4389\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1699 - mean_absolute_error: 0.4408 - val_loss: 0.1849 - val_mean_absolute_error: 0.4484\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1691 - mean_absolute_error: 0.4385 - val_loss: 0.1713 - val_mean_absolute_error: 0.4413\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1675 - mean_absolute_error: 0.4364 - val_loss: 0.1572 - val_mean_absolute_error: 0.4253\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1664 - mean_absolute_error: 0.4344 - val_loss: 0.1686 - val_mean_absolute_error: 0.4333\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1654 - mean_absolute_error: 0.4324 - val_loss: 0.1708 - val_mean_absolute_error: 0.4361\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1643 - mean_absolute_error: 0.4315 - val_loss: 0.1652 - val_mean_absolute_error: 0.4271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff225bf8d30>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Class\n",
    "### Threshold is saved with saving of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self,threshold = 1.0,**kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self,y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error)<self.threshold\n",
    "        squared_loss = tf.square(error)/2\n",
    "        linear_loss = self.threshold* tf.abs(error)-self.threshold**2/2\n",
    "        return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config,\"threshold\":self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/5_CustomModelAndTraining_HuberClass/assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=HuberLoss(2.0),optimizer=\"nadam\",metrics=[\"mae\"])\n",
    "model.save(\"../Models/5_CustomModelAndTraining_HuberClass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"../Models/5_CustomModelAndTraining_HuberClass/\",\n",
    "                               custom_objects={\"HuberLoss\":HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.1833 - mean_absolute_error: 0.4325 - val_loss: 0.2052 - val_mean_absolute_error: 0.4372\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1827 - mean_absolute_error: 0.4307 - val_loss: 0.1921 - val_mean_absolute_error: 0.4347\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1811 - mean_absolute_error: 0.4302 - val_loss: 0.2291 - val_mean_absolute_error: 0.4511\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1817 - mean_absolute_error: 0.4300 - val_loss: 0.1744 - val_mean_absolute_error: 0.4205\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1806 - mean_absolute_error: 0.4290 - val_loss: 0.2091 - val_mean_absolute_error: 0.4385\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1798 - mean_absolute_error: 0.4272 - val_loss: 0.1943 - val_mean_absolute_error: 0.4303\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1788 - mean_absolute_error: 0.4268 - val_loss: 0.2135 - val_mean_absolute_error: 0.4425\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1782 - mean_absolute_error: 0.4255 - val_loss: 0.2076 - val_mean_absolute_error: 0.4432\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1775 - mean_absolute_error: 0.4242 - val_loss: 0.1878 - val_mean_absolute_error: 0.4309\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1770 - mean_absolute_error: 0.4228 - val_loss: 0.1851 - val_mean_absolute_error: 0.4287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff225222e80>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Activation, Initializer,Reularizer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z)+1.0)\n",
    "def my_glorot_initializer(shape,dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2./(shape[0]+shape[1]))\n",
    "    return tf.random.normal(shape,stddev=stddev,dtype=dtype)\n",
    "def my_li_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01*weights))\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights<0.,tf.zeros_like(weights),weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(30,activation = my_softplus,\n",
    "                          kernel_initializer = my_glorot_initializer,\n",
    "                          kernel_regularizer=my_li_regularizer,\n",
    "                          kernel_constraint = my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self,weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor*weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\":factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self,threshold=1.0,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\",initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\",initializer=\"zeros\")\n",
    "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
    "        metric = self.huber_fn(y_true,y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true),tf.float32))\n",
    "    def result(self):\n",
    "        return self.total/self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config,\"threshold\":threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Better Implementation\n",
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.0876 - HuberMetric: 0.1753\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.0872 - HuberMetric: 0.1745\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Models/5_ModelWithCustomMetric/assets\n"
     ]
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()\n",
    "model.save(\"../Models/5_ModelWithCustomMetric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([MyDense(30, activation = 'relu', input_shape=input_shape),\n",
    "                                MyDense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8337 - val_loss: 0.6822\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.5841 - val_loss: 0.5333\n",
      "162/162 [==============================] - 0s 666us/step - loss: 0.5010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5010312795639038"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self,stddev,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "    def call(self,X,training = None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X),stddev=self.stddev)\n",
    "            return noise + X\n",
    "        else:\n",
    "            return X\n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        return batch_input_shape\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layers and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self,n_layers,n_neurons,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons,activation=\"relu\",\n",
    "                                         kernel_initializer = \"he_normal\")\n",
    "                      for _ in range(n_layers)]\n",
    "    def call(self,inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.Model):\n",
    "    def __init__(self,output_dim,**kwags):\n",
    "        super().__init__(**kwags)\n",
    "        self.hidden1 = keras.layers.Dense(30,activation=\"elu\",\n",
    "                                          kernel_initializer = \"he_normal\")\n",
    "        self.block1 = ResidualBlock(2,30)\n",
    "        self.block2 = ResidualBlock(2,30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "    def call(self, inputs):\n",
    "        Z= self.hidden1(inputs)\n",
    "        for _ in range (1+3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.5884\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4418\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7542\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6406\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.9476\n",
      "162/162 [==============================] - 0s 724us/step - loss: 0.5973\n",
      "Model: \"residual_regressor_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             multiple                  270       \n",
      "_________________________________________________________________\n",
      "residual_block_6 (ResidualBl multiple                  1860      \n",
      "_________________________________________________________________\n",
      "residual_block_7 (ResidualBl multiple                  1860      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             multiple                  31        \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_new_scaled = X_test_scaled\n",
    "\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
